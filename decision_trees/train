#!/usr/bin/env python

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import pickle
import sys
import traceback

import pandas as pd

from sklearn import tree

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

def first_col(df,colname):
    cols = list(df)
    cols.insert(0, cols.pop(cols.index(colname)))
    df = df.ix[:, cols]
    return df
    
    
# The function to execute the training.
def train():
    print('Starting the training.')
    try:
        # Read in any hyperparameters that the user passed with the training job
        with open(param_path, 'r') as tc:
            trainingParams = json.load(tc)
            print("trainingParams: ",trainingParams)
            print("Training Path: ",training_path)

        # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        if len(input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, channel_name))
        print("Reading Raw Data")
        raw_data = [ pd.read_csv(file) for file in input_files ] 
        print("Data Read In")        
        train_data = pd.concat(raw_data)
        
        print(train_data.head())
        print("Col Names:", list(train_data))
        
        # Drop NA
        train_data = train_data.dropna()
        
        # CATEGORICAL VARIABLES
        categorical_variable_cols = ['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']
        
        for var in categorical_variable_cols:
            categ_list = 'var_' + var
            categ_list = pd.get_dummies(train_data[var],prefix = var)
            train_data1=train_data.join(categ_list)
            train_data = train_data1
            
        # CATEGORICAL ENCODING

        data_vars = train_data.columns.values.tolist()
        to_keep=[i for i in data_vars if i not in categorical_variable_cols]
        train_data_final = train_data[to_keep]
        
        # FINAL COLUMNS
        columns_final = ["previous", "euribor3m", "job_blue-collar", "job_retired", "job_services", "job_student", "default_no",
        "month_aug", "month_dec", "month_jul", "month_nov", "month_oct", "month_sep", "day_of_week_fri", "day_of_week_wed",
        "poutcome_failure", "poutcome_nonexistent", "poutcome_success", "y"] 
        
        # KEEPING FINAL COLUMNS
        train_data_final  = train_data_final[columns_final]
        
        # SWITCHING Y TO FIRST COLUMNS
        train_data_final = first_col(train_data_final,'y')
        
        # labels are in the first column
        train_y = train_data_final.ix[:,0]
        train_X = train_data_final.ix[:,1:]

        # Here we only support a single hyperparameter. Note that hyperparameters are always passed in as
        # strings, so we need to do any necessary conversions.
        max_leaf_nodes = trainingParams.get('max_leaf_nodes', None)
        if max_leaf_nodes is not None:
            max_leaf_nodes = int(max_leaf_nodes)

        # Now use scikit-learn's decision tree classifier to train the model.
        clf = tree.DecisionTreeClassifier(max_leaf_nodes=max_leaf_nodes)
        clf = clf.fit(train_X, train_y)

        # save the model
        with open(os.path.join(model_path, 'decision-tree-model.pkl'), 'w') as out:
            pickle.dump(clf, out)
        print('Training complete.')
        
        
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
